{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path += ['/work/pytorch_geometric', '/work/gaas/python']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rmm\n",
    "\n",
    "rmm.reinitialize(pool_allocator=True,initial_pool_size=5e+9, maximum_pool_size=20e+9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cugraph\n",
    "from cugraph.experimental import PropertyGraph\n",
    "from cugraph.gnn.gaas_extensions import load_reddit\n",
    "G = load_reddit(None, '/work/data/reddit')\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cugraph.gnn.pyg_extensions import CuGraphData\n",
    "cd = CuGraphData(G, reserved_keys=['id','type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "TRAINING_ARGS = {\n",
    "    'batch_size':1000,\n",
    "    'fanout':[10,25],\n",
    "    'num_epochs':1,\n",
    "}\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = cd.to(device)\n",
    "#data = Data(x=cd.x, edge_index = cd.edge_index, y = cd.y) #uncomment to run w/o cugraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create the Data Loader</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "import numpy as np\n",
    "\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=TRAINING_ARGS['fanout'],\n",
    "    batch_size=TRAINING_ARGS['batch_size'],\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Define the GraphSAGE Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import LSTM\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes, num_layers):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_channels = in_channels if i == 0 else hidden_channels\n",
    "            out_channels = num_classes if i == num_layers - 1 else hidden_channels\n",
    "            self.convs.append(SAGEConv(in_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            if i != self.num_layers - 1:\n",
    "                x = x.relu()\n",
    "                x = F.dropout(x, p=0.3, training=self.training)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "num_classes = len(pd.Series(np.array(cd.y, dtype=int)).unique())\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from math import ceil\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.nn.functional import nll_loss\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import cupy\n",
    "from cuml.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "#model = SAGE(data.num_node_features, hidden_channels=256, num_classes=num_classes, num_layers=3)\n",
    "model = SAGE(data.num_node_features, hidden_channels=64, num_classes=num_classes, num_layers=1)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "num_batches = int(ceil(data.num_nodes / TRAINING_ARGS['batch_size']))\n",
    "#num_batches = 5\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, sampled_data in enumerate(tqdm.tqdm(train_loader)):\n",
    "        if i == num_batches:\n",
    "            return total_loss / data.num_nodes # FIXME is this right?\n",
    "        sampled_data = sampled_data.to(device)\n",
    "        print(f'iter: {i}')\n",
    "        print('# nodes: ', sampled_data.num_nodes)\n",
    "        print('# edges: ', sampled_data.num_edges)\n",
    "        #out = model(sampled_data.x[-1], sampled_data.edge_index[0:2])\n",
    "        out = model(sampled_data.x, sampled_data.edge_index)\n",
    "        \n",
    "        #loss = F.nll_loss(out, sampled_data.y[-1].T[0].to(torch.long))\n",
    "        loss = F.nll_loss(out, sampled_data.y.T.to(torch.long))\n",
    "        print(f'loss: {loss}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss) * out.size(0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode(loader):\n",
    "    model.eval()\n",
    "\n",
    "    xs, ys = [], []\n",
    "    for i, data in enumerate(loader):\n",
    "        print(f'encode {i}')\n",
    "        if i == num_batches:\n",
    "            break\n",
    "\n",
    "        out = model(data.x, data.edge_index)\n",
    "        xs.append(torch.argmax(out, dim=1))\n",
    "        ys.append(data.y)\n",
    "\n",
    "    return torch.cat(xs, dim=0), torch.cat(ys, dim=0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    eval_loader = LinkNeighborLoader(data, num_neighbors=TRAINING_ARGS['fanout'], batch_size=TRAINING_ARGS['batch_size'])\n",
    "    x_out, y_out = encode(eval_loader)\n",
    "\n",
    "    val_acc = 0\n",
    "    test_acc = balanced_accuracy_score(cupy.from_dlpack(y_out.__dlpack__()).get(), cupy.from_dlpack(x_out.__dlpack__()).get())\n",
    "\n",
    "    return val_acc, test_acc, x_out, y_out\n",
    "\n",
    "\n",
    "for epoch in range(1, 1 + TRAINING_ARGS['num_epochs']):\n",
    "    train_start = datetime.now()\n",
    "    loss = train()\n",
    "    train_end = datetime.now()\n",
    "    print('train time:', (train_end - train_start).total_seconds())\n",
    "\n",
    "    test_start = datetime.now()\n",
    "    val_acc, test_acc, x_out, y_out = test()\n",
    "    test_end = datetime.now()\n",
    "    print('test time:', (test_end - test_start).total_seconds())\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "          f'Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f708a36acfaef0acf74ccd43dfb58100269bf08fb79032a1e0a6f35bd9856f51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
